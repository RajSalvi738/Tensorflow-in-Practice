{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
    "# ATTENTION: Please use the provided epoch values when training.\n",
    "\n",
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 74, 74, 32)   864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 74, 74, 32)   96          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 74, 74, 32)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 72, 72, 32)   9216        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 72, 72, 32)   96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 72, 72, 32)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 72, 72, 64)   18432       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 72, 72, 64)   192         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 72, 72, 64)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 35, 35, 80)   240         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 35, 35, 80)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 33, 33, 192)  138240      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 33, 33, 192)  576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 33, 33, 192)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 16, 16, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 16, 16, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 16, 16, 96)   55296       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 16, 16, 48)   144         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 16, 16, 96)   288         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 16, 16, 48)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 16, 16, 96)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 16, 16, 64)   76800       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 16, 16, 96)   82944       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 16, 16, 64)   192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 16, 16, 64)   192         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 16, 16, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 16, 16, 32)   96          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 16, 16, 64)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 16, 16, 64)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 16, 16, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 16, 16, 32)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_193[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 16, 16, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 16, 16, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 16, 16, 96)   55296       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 16, 16, 48)   144         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 16, 16, 96)   288         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 16, 16, 48)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 16, 16, 96)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 16, 16, 64)   76800       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 16, 16, 96)   82944       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 16, 16, 64)   192         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 16, 16, 64)   192         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 16, 16, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 16, 16, 64)   192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 16, 16, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 16, 16, 64)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 16, 16, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 16, 16, 64)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 16, 16, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 16, 16, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 16, 16, 96)   55296       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 16, 16, 48)   144         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 16, 16, 96)   288         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 16, 16, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 16, 16, 96)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 16, 16, 64)   76800       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 16, 16, 96)   82944       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 16, 16, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 16, 16, 64)   192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 16, 16, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 16, 16, 64)   192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 16, 16, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 16, 16, 64)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 16, 16, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 16, 16, 64)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 16, 16, 64)   192         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 16, 16, 64)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 16, 16, 96)   55296       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 16, 16, 96)   288         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 16, 16, 96)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 7, 7, 96)     82944       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 7, 7, 384)    1152        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 7, 7, 96)     288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 7, 7, 384)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 7, 7, 96)     0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 7, 7, 128)    384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 7, 7, 128)    0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 7, 7, 128)    114688      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 7, 7, 128)    384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 7, 7, 128)    114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 7, 7, 128)    384         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 7, 7, 128)    384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 7, 7, 128)    0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 7, 7, 128)    0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 7, 7, 128)    114688      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 7, 7, 128)    114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 7, 7, 128)    384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 7, 7, 128)    384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 7, 7, 128)    0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 7, 7, 128)    0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 7, 7, 192)    172032      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 7, 7, 192)    172032      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 7, 7, 192)    576         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 7, 7, 192)    576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 7, 7, 192)    576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 7, 7, 192)    576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 7, 7, 192)    0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 7, 7, 192)    0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 7, 7, 192)    0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 7, 7, 192)    0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 7, 7, 160)    480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 7, 7, 160)    0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 7, 7, 160)    179200      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 7, 7, 160)    480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 7, 7, 160)    0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 7, 7, 160)    179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 7, 7, 160)    480         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 7, 7, 160)    480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 7, 7, 160)    0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 7, 7, 160)    0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 7, 7, 160)    179200      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 7, 7, 160)    179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 7, 7, 160)    480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 7, 7, 160)    480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 7, 7, 160)    0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 7, 7, 160)    0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 7, 7, 192)    215040      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 7, 7, 192)    215040      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 7, 7, 192)    576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 7, 7, 192)    576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 7, 7, 192)    576         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 7, 7, 192)    576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 7, 7, 192)    0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 7, 7, 192)    0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 7, 7, 192)    0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 7, 7, 192)    0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_228[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 7, 7, 160)    480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 7, 7, 160)    0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 7, 7, 160)    179200      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 7, 7, 160)    480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 7, 7, 160)    0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 7, 7, 160)    179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 7, 7, 160)    480         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 7, 7, 160)    480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 7, 7, 160)    0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 7, 7, 160)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 7, 7, 160)    179200      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 7, 7, 160)    179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 7, 7, 160)    480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 7, 7, 160)    480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 7, 7, 160)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 7, 7, 160)    0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 7, 7, 192)    215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 7, 7, 192)    215040      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 7, 7, 192)    576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 7, 7, 192)    576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 7, 7, 192)    576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 7, 7, 192)    576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 7, 7, 192)    0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 7, 7, 192)    0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 7, 7, 192)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 7, 7, 192)    0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 7, 7, 192)    576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 7, 7, 192)    0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 7, 7, 192)    258048      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 7, 7, 192)    576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 7, 7, 192)    0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 7, 7, 192)    258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 7, 7, 192)    576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 7, 7, 192)    576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 7, 7, 192)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 7, 7, 192)    0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 7, 7, 192)    258048      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 7, 7, 192)    258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 7, 7, 192)    576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 7, 7, 192)    576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 7, 7, 192)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 7, 7, 192)    0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 7, 7, 192)    258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 7, 7, 192)    258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 7, 7, 192)    576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 7, 7, 192)    576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 7, 7, 192)    576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 7, 7, 192)    576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 7, 7, 192)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 7, 7, 192)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 7, 7, 192)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 7, 7, 192)    0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 7, 7, 192)    576         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 7, 7, 192)    0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 7, 7, 192)    258048      activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 7, 7, 192)    576         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 7, 7, 192)    0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 7, 7, 192)    258048      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 7, 7, 192)    576         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 7, 7, 192)    576         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 7, 7, 192)    0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 7, 7, 192)    0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 3, 3, 320)    552960      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 3, 3, 192)    331776      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 3, 3, 320)    960         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 3, 3, 192)    576         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 3, 3, 320)    0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 3, 3, 192)    0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_259[0][0]             \n",
      "                                                                 activation_263[0][0]             \n",
      "                                                                 max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 3, 3, 448)    1344        conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 3, 3, 448)    0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 3, 3, 384)    1548288     activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 3, 3, 384)    1152        conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 3, 3, 384)    1152        conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 3, 3, 384)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 3, 3, 384)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 3, 3, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 3, 3, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 3, 3, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 3, 3, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 3, 3, 384)    1152        conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 3, 3, 384)    1152        conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 3, 3, 384)    1152        conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 3, 3, 384)    1152        conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 3, 3, 320)    960         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 3, 3, 384)    0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 3, 3, 384)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 3, 3, 384)    0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 3, 3, 384)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 3, 3, 192)    576         conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 3, 3, 320)    0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_266[0][0]             \n",
      "                                                                 activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3, 3, 768)    0           activation_270[0][0]             \n",
      "                                                                 activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 3, 3, 192)    0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_264[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 3, 3, 448)    1344        conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 3, 3, 448)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 3, 3, 384)    1548288     activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 3, 3, 384)    1152        conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 3, 3, 384)    1152        conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 3, 3, 384)    0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 3, 3, 384)    0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 3, 3, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 3, 3, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 3, 3, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 3, 3, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 3, 3, 384)    1152        conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 3, 3, 384)    1152        conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 3, 3, 384)    1152        conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 3, 3, 384)    1152        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 3, 3, 320)    960         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 3, 3, 384)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 3, 3, 384)    0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 3, 3, 384)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 3, 3, 384)    0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
      "                                                                 activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 activation_281[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = path_inception\n",
    "\n",
    "pre_trained_model = InceptionV3(\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False,\n",
    "    weights=None)# Your Code Here\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "  # Your Code Here\n",
    "    layer.trainable = False\n",
    "  \n",
    "# Print the model summary\n",
    "pre_trained_model.summary()\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output# Your Code Here\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('acc')>0.97):\n",
    "            print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 74, 74, 32)   864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 74, 74, 32)   96          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 74, 74, 32)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 72, 72, 32)   9216        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 72, 72, 32)   96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 72, 72, 32)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 72, 72, 64)   18432       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 72, 72, 64)   192         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 72, 72, 64)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 35, 35, 80)   240         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 35, 35, 80)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 33, 33, 192)  138240      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 33, 33, 192)  576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 33, 33, 192)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 16, 16, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 16, 16, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 16, 16, 96)   55296       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 16, 16, 48)   144         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 16, 16, 96)   288         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 16, 16, 48)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 16, 16, 96)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 16, 16, 64)   76800       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 16, 16, 96)   82944       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 16, 16, 64)   192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 16, 16, 64)   192         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 16, 16, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 16, 16, 32)   96          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 16, 16, 64)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 16, 16, 64)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 16, 16, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 16, 16, 32)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_193[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 16, 16, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 16, 16, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 16, 16, 96)   55296       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 16, 16, 48)   144         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 16, 16, 96)   288         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 16, 16, 48)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 16, 16, 96)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 16, 16, 64)   76800       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 16, 16, 96)   82944       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 16, 16, 64)   192         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 16, 16, 64)   192         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 16, 16, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 16, 16, 64)   192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 16, 16, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 16, 16, 64)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 16, 16, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 16, 16, 64)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 16, 16, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 16, 16, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 16, 16, 96)   55296       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 16, 16, 48)   144         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 16, 16, 96)   288         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 16, 16, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 16, 16, 96)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 16, 16, 64)   76800       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 16, 16, 96)   82944       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 16, 16, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 16, 16, 64)   192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 16, 16, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 16, 16, 64)   192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 16, 16, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 16, 16, 64)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 16, 16, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 16, 16, 64)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 16, 16, 64)   192         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 16, 16, 64)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 16, 16, 96)   55296       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 16, 16, 96)   288         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 16, 16, 96)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 7, 7, 96)     82944       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 7, 7, 384)    1152        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 7, 7, 96)     288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 7, 7, 384)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 7, 7, 96)     0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 7, 7, 128)    384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 7, 7, 128)    0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 7, 7, 128)    114688      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 7, 7, 128)    384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 7, 7, 128)    114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 7, 7, 128)    384         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 7, 7, 128)    384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 7, 7, 128)    0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 7, 7, 128)    0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 7, 7, 128)    114688      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 7, 7, 128)    114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 7, 7, 128)    384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 7, 7, 128)    384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 7, 7, 128)    0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 7, 7, 128)    0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 7, 7, 192)    172032      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 7, 7, 192)    172032      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 7, 7, 192)    576         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 7, 7, 192)    576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 7, 7, 192)    576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 7, 7, 192)    576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 7, 7, 192)    0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 7, 7, 192)    0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 7, 7, 192)    0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 7, 7, 192)    0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 7, 7, 160)    480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 7, 7, 160)    0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 7, 7, 160)    179200      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 7, 7, 160)    480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 7, 7, 160)    0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 7, 7, 160)    179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 7, 7, 160)    480         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 7, 7, 160)    480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 7, 7, 160)    0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 7, 7, 160)    0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 7, 7, 160)    179200      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 7, 7, 160)    179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 7, 7, 160)    480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 7, 7, 160)    480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 7, 7, 160)    0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 7, 7, 160)    0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 7, 7, 192)    215040      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 7, 7, 192)    215040      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 7, 7, 192)    576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 7, 7, 192)    576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 7, 7, 192)    576         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 7, 7, 192)    576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 7, 7, 192)    0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 7, 7, 192)    0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 7, 7, 192)    0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 7, 7, 192)    0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_228[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 7, 7, 160)    480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 7, 7, 160)    0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 7, 7, 160)    179200      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 7, 7, 160)    480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 7, 7, 160)    0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 7, 7, 160)    179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 7, 7, 160)    480         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 7, 7, 160)    480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 7, 7, 160)    0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 7, 7, 160)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 7, 7, 160)    179200      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 7, 7, 160)    179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 7, 7, 160)    480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 7, 7, 160)    480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 7, 7, 160)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 7, 7, 160)    0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 7, 7, 192)    215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 7, 7, 192)    215040      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 7, 7, 192)    576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 7, 7, 192)    576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 7, 7, 192)    576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 7, 7, 192)    576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 7, 7, 192)    0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 7, 7, 192)    0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 7, 7, 192)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 7, 7, 192)    0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 7, 7, 192)    576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 7, 7, 192)    0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 7, 7, 192)    258048      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 7, 7, 192)    576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 7, 7, 192)    0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 7, 7, 192)    258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 7, 7, 192)    576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 7, 7, 192)    576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 7, 7, 192)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 7, 7, 192)    0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 7, 7, 192)    258048      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 7, 7, 192)    258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 7, 7, 192)    576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 7, 7, 192)    576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 7, 7, 192)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 7, 7, 192)    0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 7, 7, 192)    258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 7, 7, 192)    258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 7, 7, 192)    576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 7, 7, 192)    576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 7, 7, 192)    576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 7, 7, 192)    576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 7, 7, 192)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 7, 7, 192)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 7, 7, 192)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 7, 7, 192)    0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1024)         38536192    flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            1025        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)         \n",
    "\n",
    "model = Model(pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree('/tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "train_horses_dir = os.path.join(train_dir, 'horses')# Your Code Here\n",
    "train_humans_dir = os.path.join(train_dir, 'humans')# Your Code Here\n",
    "validation_horses_dir = os.path.join(validation_dir, 'horses')# Your Code Here\n",
    "validation_humans_dir = os.path.join(validation_dir, 'humans')# Your Code Here\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir)# Your Code Here\n",
    "train_humans_fnames = os.listdir(train_humans_dir)# Your Code Here\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir)# Your Code Here\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir)# Your Code Here\n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames))\n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_humans_fnames))\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255.)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    target_size=(150,150))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    target_size=(150,150))\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "52/52 [==============================] - 57s 1s/step - loss: 0.2522 - acc: 0.9056 - val_loss: 0.0347 - val_acc: 0.9883\n",
      "Epoch 2/3\n",
      "51/52 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9811\n",
      "Reached 97.0% accuracy so cancelling training!\n",
      "52/52 [==============================] - 48s 919ms/step - loss: 0.0567 - acc: 0.9815 - val_loss: 0.0012 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 97% accuracy\n",
    "\n",
    "callbacks = myCallback() # Your Code Here\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=3,\n",
    "    validation_data = validation_generator,\n",
    "    callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This will free up resources for your fellow learners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "<!-- Save the notebook -->\n",
       "IPython.notebook.save_checkpoint();\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.session.delete();\n",
    "window.onbeforeunload = null\n",
    "setTimeout(function() { window.close(); }, 1000);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
